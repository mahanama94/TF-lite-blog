{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-Lite-Demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahanama94/TF-lite-blog/blob/main/TF_Lite_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2021-12-20 Machine Learning on Mobile and Embedded Devices\n",
        "\n",
        "Supplementary material for the blog post [2021-12-20 Machine Learning on Mobile and Embedded Devices](https://ws-dl.blogspot.com/2021/12/2021-12-20-machine-learning-on-mobile.html) on [Web Science and Digital Libraries Research Group Blog.](https://ws-dl.blogspot.com/)\n",
        "\n",
        "For related articles and news:\n",
        "\n",
        "* [Web Science and Digital Libraries Research Group](https://oduwsdl.github.io/)\n",
        "* [Neuro-Information Retrieval and Data Science (NIRDS) Lab](https://nirdslab.github.io/)\n",
        "\n",
        "Social media (Twitter):\n",
        "\n",
        "* [@WebSciDL](https://twitter.com/WebSciDL)\n",
        "* [@NirdsLab](https://twitter.com/NirdsLab)\n",
        "\n",
        "YouTube: \n",
        "\n",
        "* [Nirds Lab](https://www.youtube.com/channel/UCWpcGyC2vCecKB5AFJWJ3ow)\n",
        "\n",
        "\n",
        "For more detailed arttcles/tutorials:\n",
        "* [TensorFlow Lite official guide](https://www.tensorflow.org/lite/guide)\n"
      ],
      "metadata": {
        "id": "Ia42ue-qY_Ng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M0Pw9YBZvQrx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# \n",
        "# Evaluation code credits: https://github.com/tensorflow/tensorflow (TensorFlow)\n",
        "# Colab Notebook: https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_quant.ipynb#scrollTo=05aeAuWjvjPx\n",
        "# Github : https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_quantization.md\n",
        "# \n",
        "# \n",
        "\n",
        "def evaluate_model(interpreter, x_test, y_test):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(x_test):\n",
        "    # if i % 1000 == 0:\n",
        "    #   print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == y_test).mean()\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "PgzCowbF4Pfe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train) , (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "JmhkZvRhvboG",
        "outputId": "784c42e5-46f5-46f7-c8d2-ae605e1a1f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[10])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "TEJSbNlov1W3",
        "outputId": "a5935617-fd88-47e3-b469-89e9eb261821"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255\n",
        "\n",
        "x_test = x_test / 255"
      ],
      "metadata": {
        "id": "FUE80ejgv714"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Model"
      ],
      "metadata": {
        "id": "iv4l6FpVNYL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Flatten\n",
        "\n",
        "def get_base_model():\n",
        "    return Sequential([\n",
        "                        InputLayer(input_shape=(28, 28)),\n",
        "                        Flatten(),\n",
        "                        Dense(128, activation='relu'),\n",
        "                        Dense(32, activation='relu'),\n",
        "                        Dense(10, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "base_model = get_base_model()\n",
        "\n",
        "base_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "base_model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpYK0u3UwQlj",
        "outputId": "6c97b94b-1d07-4e3f-f2b1-a3630073aae6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2586 - accuracy: 0.9245\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1070 - accuracy: 0.9673\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0770 - accuracy: 0.9756\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0567 - accuracy: 0.9818\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0455 - accuracy: 0.9853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38350603d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhgDRFPbxm3K",
        "outputId": "401e9a33-4d3b-489c-b311-84f064d277ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9741\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08912268280982971, 0.9740999937057495]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.save(\"base-mnist-model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwitPA71xxje",
        "outputId": "0759a21e-91b0-4f40-a899-58ed999c5a91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: base-mnist-model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-training Quantization"
      ],
      "metadata": {
        "id": "Mm-OMY33ySfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_converter = tf.lite.TFLiteConverter.from_saved_model(\"base-mnist-model\")"
      ],
      "metadata": {
        "id": "2rqJTIpbyJdA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Quantized Conversion"
      ],
      "metadata": {
        "id": "2AMGzpxF9RMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model = tflite_converter.convert()\n",
        "\n",
        "NON_QUANTIZED_MODEL = \"mnist-tflite-model.tflite\"\n",
        "\n",
        "with open(NON_QUANTIZED_MODEL, \"wb\") as model_file:\n",
        "    model_file.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO9PTjsUy6Pg",
        "outputId": "b89653f6-ad64-4c22-882f-415659e92d51"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantized Conversion"
      ],
      "metadata": {
        "id": "-cUSVaCT9U0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_tflite_converter = tf.lite.TFLiteConverter.from_saved_model(\"base-mnist-model\")\n",
        "\n",
        "quantized_tflite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_quantized_model = quantized_tflite_converter.convert()\n",
        "\n",
        "QUANTIZED_MODEL = \"mnist-tflite-quantized-model.tflite\"\n",
        "\n",
        "with open(QUANTIZED_MODEL, \"wb\") as model_file:\n",
        "    model_file.write(tflite_quantized_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEaJiGdxzji1",
        "outputId": "5673a264-e71f-4631-86bd-8ae45542f03c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Size Comparison"
      ],
      "metadata": {
        "id": "0_E3-t1v9osB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'''TF Lite base model size : {os.path.getsize(NON_QUANTIZED_MODEL) / float(2**10)}\n",
        "Quantized model size: {os.path.getsize(QUANTIZED_MODEL) / float(2**10)}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp29roDW0M__",
        "outputId": "2d36e37f-d12a-4041-e8cf-763f1686e13c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Lite base model size : 411.953125\n",
            "Quantized model size: 106.15625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy Comparison"
      ],
      "metadata": {
        "id": "D59t-KaO9rJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_quantized_model)\n",
        "interpreter.allocate_tensors()\n",
        "quantized_tflite_model_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "tflite_model_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
        "\n",
        "print(f'''TF Lite base model accuracy: {tflite_model_accuracy} \n",
        "Quantized model accuracy: {quantized_tflite_model_accuracy}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKbQZWC28POu",
        "outputId": "49f227d3-8e91-4426-952c-f8d09c15db75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Lite base model accuracy: 0.974 \n",
            "Quantized model accuracy: 0.9738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization Aware Training"
      ],
      "metadata": {
        "id": "ZBEg6Iez7wMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3nM-VrS1OCG",
        "outputId": "4a88bbbe-53e5-4a21-ab14-ad38407584e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 213 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (0.1.6)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4jKMi3nv9wuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantization_aware_model = tfmot.quantization.keras.quantize_model(\n",
        "    get_base_model()\n",
        ")\n",
        "\n",
        "quantization_aware_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "quantization_aware_model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUN_ol1N0zVI",
        "outputId": "c05d2f0d-6bde-4fc8-acbf-7151550626f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2594 - accuracy: 0.9248\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1088 - accuracy: 0.9673\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0777 - accuracy: 0.9760\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0602 - accuracy: 0.9810\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0468 - accuracy: 0.9852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f382bb81b10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy Comparison"
      ],
      "metadata": {
        "id": "VSb_Winj92GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_loss, base_model_accuracy = base_model.evaluate(x_test, y_test)\n",
        "\n",
        "quantization_aware_model_loss, quantization_aware_model_accuracy = quantization_aware_model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f'''Base model accuracy: {base_model_accuracy}\n",
        "Quantization aware model accuracy : {quantization_aware_model_accuracy}''')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iOkWy-X3SC5",
        "outputId": "b2db0f49-cd54-415d-a119-491163a46319"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9741\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9729\n",
            "Base model accuracy: 0.9740999937057495\n",
            "Quantization aware model accuracy : 0.9728999733924866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(quantization_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_aware_tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKHA8ugR4mOk",
        "outputId": "36ca6f85-ca11-45c3-ea26-6e02265311b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as flatten_1_layer_call_fn, flatten_1_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp78h_e8ho/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp78h_e8ho/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converted Model Accuracy Comparison"
      ],
      "metadata": {
        "id": "Y_H2tevz9_xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_aware_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "quantized_aware_model_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
        "\n",
        "print(f'''Quantized model accuracy: {quantized_aware_model_accuracy} \n",
        "Quantization aware model accuracy: {quantization_aware_model_accuracy}\n",
        "Base model accuracy: {base_model_accuracy}''')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px2wXKMh4z8I",
        "outputId": "bef9bfb2-c7ba-408d-dd87-302fadeeaa59"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model accuracy: 0.9336 \n",
            "Quantization aware model accuracy: 0.9728999733924866\n",
            "Base model accuracy: 0.9740999937057495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Size Comparison"
      ],
      "metadata": {
        "id": "ekxkkWdJ-Fpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUANTIZED_AWARE_MODEL = \"mnist-tflite-quantized-aware-model.tflite\"\n",
        "\n",
        "with open(QUANTIZED_AWARE_MODEL, \"wb\") as model_file:\n",
        "    model_file.write(quantized_aware_tflite_model)\n",
        "\n",
        "print(f'''Non-quantized model size : {os.path.getsize(NON_QUANTIZED_MODEL) / float(2**10)}\n",
        "Quantized model size (With Quantiaztion-aware training): {os.path.getsize(QUANTIZED_AWARE_MODEL) / float(2**10)}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V-c5q5w-HQj",
        "outputId": "339296bd-fbfe-42ca-84ec-5a71af1ec8bd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-quantized model size : 411.953125\n",
            "Quantized model size (With Quantiaztion-aware training): 106.09375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "rbtwwWzBEcAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 16,\n",
        "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
        "}\n",
        "\n",
        "# Cluster a whole model\n",
        "clustered_model = cluster_weights(base_model, **clustering_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "clustered_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "clustered_model.summary()\n",
        "\n",
        "clustered_model.fit(x_train, y_train, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9XfoT-yEdz1",
        "outputId": "62b2f71d-4b4d-4990-8df3-6af1b9f022ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " cluster_flatten (ClusterWei  (None, 784)              0         \n",
            " ghts)                                                           \n",
            "                                                                 \n",
            " cluster_dense (ClusterWeigh  (None, 128)              200848    \n",
            " ts)                                                             \n",
            "                                                                 \n",
            " cluster_dense_1 (ClusterWei  (None, 32)               8240      \n",
            " ghts)                                                           \n",
            "                                                                 \n",
            " cluster_dense_2 (ClusterWei  (None, 10)               666       \n",
            " ghts)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,754\n",
            "Trainable params: 104,986\n",
            "Non-trainable params: 104,768\n",
            "_________________________________________________________________\n",
            "1875/1875 [==============================] - 44s 22ms/step - loss: 0.0445 - accuracy: 0.9849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38adf07e10>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy Comparison"
      ],
      "metadata": {
        "id": "DP61lwvGL-Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_model_loss, clustered_model_accuracy = clustered_model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f'''Base model accuracy : {base_model_accuracy}\n",
        "Clustered model accuracy: {clustered_model_accuracy}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ALXfGO2IsMj",
        "outputId": "fa06bd5c-ed6a-42eb-8689-a022fdcfd208"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 14ms/step - loss: 0.0965 - accuracy: 0.9735\n",
            "Base model accuracy : 0.9740999937057495\n",
            "Clustered model accuracy: 0.9735000133514404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLUSTERED_MODEL = \"mnist-tflite-clustered-model.tflite\"\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(tfmot.clustering.keras.strip_clustering(clustered_model))\n",
        "\n",
        "clustered_tflite_model = converter.convert()\n",
        "\n",
        "with open(CLUSTERED_MODEL, \"wb\") as model_file:\n",
        "    model_file.write(clustered_tflite_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTHJy132JPd-",
        "outputId": "301be33c-fa73-452a-fe2d-5e0607bb9ebf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp6szlzmkt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp6szlzmkt/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zipped Size Comparison"
      ],
      "metadata": {
        "id": "e3yU7Uk0L3M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip  mnist-tflite-model.zip mnist-tflite-model.tflite\n",
        "!zip  mnist-tflite-clustered-model.zip mnist-tflite-clustered-model.tflite\n",
        "!ls -hs | grep zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-QiXNbGKmkU",
        "outputId": "09cda7d6-03c6-4c24-8a1d-f2a905fa03d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: mnist-tflite-model.tflite (deflated 7%)\n",
            "  adding: mnist-tflite-clustered-model.tflite (deflated 87%)\n",
            " 56K mnist-tflite-clustered-model.zip\n",
            "384K mnist-tflite-model.zip\n"
          ]
        }
      ]
    }
  ]
}