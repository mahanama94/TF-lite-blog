{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-Lite-Demo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPB3bwdkK6S0/6wukATJwjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahanama94/TF-lite-blog/blob/main/TF_Lite_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0Pw9YBZvQrx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter, x_test, y_test):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(x_test):\n",
        "    # if i % 1000 == 0:\n",
        "    #   print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == y_test).mean()\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "PgzCowbF4Pfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train) , (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "JmhkZvRhvboG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[10])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "TEJSbNlov1W3",
        "outputId": "40b0271b-69fe-4e5e-b865-8b2daa541433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255\n",
        "\n",
        "x_test = x_test / 255"
      ],
      "metadata": {
        "id": "FUE80ejgv714"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Model"
      ],
      "metadata": {
        "id": "iv4l6FpVNYL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Flatten\n",
        "\n",
        "def get_base_model():\n",
        "    return Sequential([\n",
        "                        InputLayer(input_shape=(28, 28)),\n",
        "                        Flatten(),\n",
        "                        Dense(128, activation='relu'),\n",
        "                        Dense(32, activation='relu'),\n",
        "                        Dense(10, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "base_model = get_base_model()\n",
        "\n",
        "base_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "base_model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpYK0u3UwQlj",
        "outputId": "78fe3fac-c63a-49f8-f633-74831aba3133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2696 - accuracy: 0.9205\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1142 - accuracy: 0.9665\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0780 - accuracy: 0.9758\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0601 - accuracy: 0.9813\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0460 - accuracy: 0.9854\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce41713550>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhgDRFPbxm3K",
        "outputId": "450f939c-bd01-4a6b-a8dd-32e07f733192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9717\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09013017266988754, 0.9717000126838684]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.save(\"base-mnist-model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwitPA71xxje",
        "outputId": "64dfbe94-2df9-4175-b90d-76b5554acce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: base-mnist-model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: base-mnist-model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-training Quantization"
      ],
      "metadata": {
        "id": "Mm-OMY33ySfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_converter = tf.lite.TFLiteConverter.from_saved_model(\"base-mnist-model\")"
      ],
      "metadata": {
        "id": "2rqJTIpbyJdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Quantized Conversion"
      ],
      "metadata": {
        "id": "2AMGzpxF9RMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model = tflite_converter.convert()\n",
        "\n",
        "NON_QUANTIZED_MODEL = \"mnist-tflite-model.tflite\"\n",
        "\n",
        "with open(NON_QUANTIZED_MODEL, \"wb\") as model_file:\n",
        "    model_file.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO9PTjsUy6Pg",
        "outputId": "e7c48230-e129-4374-b751-199a70e2af64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantized Conversion"
      ],
      "metadata": {
        "id": "-cUSVaCT9U0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_quantized_model = tflite_converter.convert()\n",
        "\n",
        "QUANTIZED_MODEL = \"mnist-tflite-quantized-model.tflite\"\n",
        "\n",
        "with open(QUANTIZED_MODEL, \"wb\") as model_file:\n",
        "    model_file.write(tflite_quantized_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEaJiGdxzji1",
        "outputId": "4175842e-786c-4ab4-b8af-d421a7c0cfc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Size Comparison"
      ],
      "metadata": {
        "id": "0_E3-t1v9osB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'''TF Lite base model size : {os.path.getsize(NON_QUANTIZED_MODEL) / float(2**10)}\n",
        "Quantized model size: {os.path.getsize(QUANTIZED_MODEL) / float(2**10)}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp29roDW0M__",
        "outputId": "f7efb02b-cf4c-47dc-e10d-7401efafeca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-quantized model size : 412.02734375\n",
            "Quantized model size: 106.234375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy Comparison"
      ],
      "metadata": {
        "id": "D59t-KaO9rJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_quantized_model)\n",
        "interpreter.allocate_tensors()\n",
        "quantized_tflite_model_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "tflite_model_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
        "\n",
        "print(f'''TF Lite base model accuracy: {tflite_model_accuracy} \n",
        "Quantized model accuracy: {quantized_tflite_model_accuracy}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKbQZWC28POu",
        "outputId": "93c909e4-b63d-41dc-dd1d-5ff9905493f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-quantized model accuracy: 0.9717 \n",
            "Quantized model accuracy: 0.9715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization Aware Training"
      ],
      "metadata": {
        "id": "ZBEg6Iez7wMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3nM-VrS1OCG",
        "outputId": "bfe67aa0-f668-4db2-8437-e3a00812e3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (0.1.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4jKMi3nv9wuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantization_aware_model = tfmot.quantization.keras.quantize_model(\n",
        "    get_base_model()\n",
        ")\n",
        "\n",
        "quantization_aware_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "quantization_aware_model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUN_ol1N0zVI",
        "outputId": "a636fbde-f04f-42f0-a6c2-6e45fc1ccc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2524 - accuracy: 0.9262\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1078 - accuracy: 0.9672\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0762 - accuracy: 0.9765\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0567 - accuracy: 0.9821\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0448 - accuracy: 0.9854\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce49472490>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy Comparison"
      ],
      "metadata": {
        "id": "VSb_Winj92GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_loss, base_model_accuracy = base_model.evaluate(x_test, y_test)\n",
        "\n",
        "quantization_aware_model_loss, quantization_aware_model_accuracy = quantization_aware_model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f'''Base model accuracy: {base_model_accuracy}\n",
        "Quantization aware model accuracy : {quantization_aware_model_accuracy}''')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iOkWy-X3SC5",
        "outputId": "08b2e7fa-7fbc-410d-ce8c-0fbc291ed4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9717\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9730\n",
            "Base model accuracy: 0.9717000126838684\n",
            "Quantization aware model accuracy : 0.9729999899864197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(quantization_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_aware_tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKHA8ugR4mOk",
        "outputId": "50e067ea-36b3-4814-c7a5-305c620f27bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as flatten_10_layer_call_fn, flatten_10_layer_call_and_return_conditional_losses, dense_30_layer_call_fn, dense_30_layer_call_and_return_conditional_losses, dense_31_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp07gd67ve/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp07gd67ve/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converted Model Accuracy Comparison"
      ],
      "metadata": {
        "id": "Y_H2tevz9_xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_aware_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "quantized_aware_model_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
        "\n",
        "print(f'''Quantized model accuracy: {quantized_aware_model_accuracy} \n",
        "Quantization aware model accuracy: {quantization_aware_model_accuracy}\n",
        "Base model accuracy: {base_model_accuracy}''')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px2wXKMh4z8I",
        "outputId": "7540b89b-907d-4708-b4e5-67f30b4f7f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model accuracy: 0.9071 \n",
            "Quantization aware model accuracy: 0.9729999899864197\n",
            "Base model accuracy: 0.9717000126838684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Size Comparison"
      ],
      "metadata": {
        "id": "ekxkkWdJ-Fpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUANTIZED_AWARE_MODEL = \"mnist-tflite-quantized-aware-model.tflite\"\n",
        "\n",
        "with open(QUANTIZED_AWARE_MODEL, \"wb\") as model_file:\n",
        "    model_file.write(quantized_aware_tflite_model)\n",
        "\n",
        "print(f'''Non-quantized model size : {os.path.getsize(NON_QUANTIZED_MODEL) / float(2**10)}\n",
        "Quantized model size (With Quantiaztion-aware training): {os.path.getsize(QUANTIZED_AWARE_MODEL) / float(2**10)}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V-c5q5w-HQj",
        "outputId": "66dadecd-0cb9-4b4d-e878-91678f2cbe44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-quantized model size : 412.02734375\n",
            "Quantized model size (With Quantiaztion-aware training): 106.1484375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "rbtwwWzBEcAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 16,\n",
        "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
        "}\n",
        "\n",
        "# Cluster a whole model\n",
        "clustered_model = cluster_weights(base_model, **clustering_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "clustered_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "clustered_model.summary()\n",
        "\n",
        "clustered_model.fit(x_train, y_train, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9XfoT-yEdz1",
        "outputId": "cc4e5c9c-0f17-426a-b788-cc8b8f7f787e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " cluster_flatten_9 (ClusterW  (None, 784)              0         \n",
            " eights)                                                         \n",
            "                                                                 \n",
            " cluster_dense_27 (ClusterWe  (None, 128)              200848    \n",
            " ights)                                                          \n",
            "                                                                 \n",
            " cluster_dense_28 (ClusterWe  (None, 32)               8240      \n",
            " ights)                                                          \n",
            "                                                                 \n",
            " cluster_dense_29 (ClusterWe  (None, 10)               666       \n",
            " ights)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,754\n",
            "Trainable params: 104,986\n",
            "Non-trainable params: 104,768\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy Comparison"
      ],
      "metadata": {
        "id": "DP61lwvGL-Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_model_loss, clustered_model_accuracy = clustered_model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f'''Base model accuracy : {base_model_accuracy}\n",
        "Clustered model accuracy: {clustered_model_accuracy}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ALXfGO2IsMj",
        "outputId": "0d0a9330-f899-4e3f-aa1d-4053e285d57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0807 - accuracy: 0.9757\n",
            "Base model accuracy : 0.9717000126838684\n",
            "Clustered model accuracy: 0.9757000207901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLUSTERED_MODEL = \"mnist-tflite-clustered-model.tflite\"\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(tfmot.clustering.keras.strip_clustering(clustered_model))\n",
        "\n",
        "clustered_tflite_model = converter.convert()\n",
        "\n",
        "with open(CLUSTERED_MODEL, \"wb\") as model_file:\n",
        "    model_file.write(clustered_tflite_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTHJy132JPd-",
        "outputId": "6577d75c-4f3c-4d75-9181-89ebdc34dcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmph00cuycq/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmph00cuycq/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zipped Size Comparison"
      ],
      "metadata": {
        "id": "e3yU7Uk0L3M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip  mnist-tflite-model.zip mnist-tflite-model.tflite\n",
        "!zip  mnist-tflite-clustered-model.zip mnist-tflite-clustered-model.tflite\n",
        "!ls -hs | grep zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-QiXNbGKmkU",
        "outputId": "21951bd3-a372-4de5-da1b-0386277a4ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: mnist-tflite-model.tflite (deflated 7%)\n",
            "updating: mnist-tflite-clustered-model.tflite (deflated 87%)\n",
            " 56K mnist-tflite-clustered-model.zip\n",
            "384K mnist-tflite-model.zip\n"
          ]
        }
      ]
    }
  ]
}